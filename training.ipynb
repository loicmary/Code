{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap = pd.read_csv('dap_2018-2023.csv', sep=';', parse_dates=['Unnamed: 0']).rename(columns={\"Unnamed: 0\":'Timestamp', '0':'DAP'})\n",
    "forecast_load = pd.read_csv('forecast_load_2018-2023.csv', sep=';', parse_dates=['Unnamed: 0']).rename(columns={'Unnamed: 0':'Timestamp'})\n",
    "forecast_renewable = pd.read_csv('Forecast_renewable_2018-2023.csv', sep=';', parse_dates=['Unnamed: 0']).rename(columns={'Unnamed: 0':'Timestamp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARY Loïc\\AppData\\Local\\Temp\\ipykernel_6468\\4130534214.py:2: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  dap = dap.interpolate()\n"
     ]
    }
   ],
   "source": [
    "dap.loc[dap['DAP']>= 2000, 'DAP'] = np.nan\n",
    "dap = dap.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 41052)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap.isna().sum().sum(), forecast_load.isna().sum().sum(), forecast_renewable.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_parser(s):\n",
    "    return pd.to_datetime(s['Timestamp'], utc=True).dt.tz_convert('Europe/Paris').dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap['Timestamp'] = timestamp_parser(dap)\n",
    "forecast_load['Timestamp'] = timestamp_parser(forecast_load)\n",
    "forecast_renewable['Timestamp'] = timestamp_parser(forecast_renewable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap.drop_duplicates(subset='Timestamp', keep='last', inplace=True)\n",
    "forecast_load.drop_duplicates(subset='Timestamp', keep='last', inplace=True)\n",
    "forecast_renewable.drop_duplicates(subset='Timestamp', keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 41049)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap.isna().sum().sum(), forecast_load.isna().sum().sum(), forecast_renewable.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_renewable.fillna(value=0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap.isna().sum().sum(), forecast_load.isna().sum().sum(), forecast_renewable.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_renewable['Wind'] = forecast_renewable['Wind Offshore'] + forecast_renewable['Wind Onshore']\n",
    "forecast_renewable.drop(columns=['Wind Offshore', 'Wind Onshore'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_moving_average(df):\n",
    "    if df.isna().any().sum()>0:\n",
    "        return df.fillna((df.ffill() + df.bfill())/2, inplace=False)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_load = fillna_moving_average(forecast_load.set_index('Timestamp').resample('h').mean()).reset_index()\n",
    "forecast_renewable=fillna_moving_average(forecast_renewable.set_index('Timestamp').resample('h').mean()).reset_index()\n",
    "dap = fillna_moving_average(dap.set_index('Timestamp').resample('h').mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap.isna().sum().sum(), forecast_load.isna().sum().sum(), forecast_renewable.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reduce(lambda df1,df2:pd.merge(df1,df2, on='Timestamp'), [dap, forecast_load, forecast_renewable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp          0\n",
       "DAP                0\n",
       "Forecasted Load    0\n",
       "Solar              0\n",
       "Wind               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Residual_Demand'] = df['Forecasted Load'] - df['Solar'] - df['Wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Solar','Wind','Forecasted Load'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARY Loïc\\AppData\\Local\\Temp\\ipykernel_6468\\354213036.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df2 = df.drop(columns=['Timestamp']).groupby(['Date'], group_keys=False).apply(lambda x:x.drop(columns=['Date']).values.reshape((1,48))).reset_index()\n"
     ]
    }
   ],
   "source": [
    "df2 = df.drop(columns=['Timestamp']).groupby(['Date'], group_keys=False).apply(lambda x:x.drop(columns=['Date']).values.reshape((1,48))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[0].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['A'] = df2[0].apply(lambda x:x.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[item for sublist in zip([f'DAP{i}' for i in range(24)], [f'FRD{i}' for i in range(24)]) for item in sublist]] = df2['A'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=[0,'A'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2[[f'DAP{i}' for i in range(24)]]\n",
    "X = df2[[f'FRD{i}' for i in range(24)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56859., 53558., 52054., ..., 49405., 49259., 52641.],\n",
       "       [49249., 45931., 44183., ..., 45708., 43952., 46982.],\n",
       "       [44525., 41357., 40440., ..., 50455., 48569., 52230.],\n",
       "       ...,\n",
       "       [39563., 36971., 36466., ..., 43717., 42588., 44865.],\n",
       "       [42237., 39997., 40029., ..., 37054., 36866., 38231.],\n",
       "       [35588., 32520., 30963., ..., 33642., 34910., 37230.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08529983, 0.09006682, 0.09589317, ..., 0.03981327, 0.07442037,\n",
       "        0.07983589],\n",
       "       [0.07153802, 0.06875271, 0.06923375, ..., 0.04639009, 0.06126731,\n",
       "        0.07064806],\n",
       "       [0.0559958 , 0.04774794, 0.05380017, ..., 0.05218396, 0.065844  ,\n",
       "        0.06720926],\n",
       "       ...,\n",
       "       [0.00049618, 0.00371218, 0.01124136, ..., 0.01952494, 0.03505298,\n",
       "        0.0253462 ],\n",
       "       [0.01989113, 0.01924148, 0.02504464, ..., 0.02815702, 0.06579155,\n",
       "        0.05750362],\n",
       "       [0.02670636, 0.01132216, 0.01746759, ..., 0.00802529, 0.01409725,\n",
       "        0.00493912]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_y.fit_transform(Y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRD0</th>\n",
       "      <th>FRD1</th>\n",
       "      <th>FRD2</th>\n",
       "      <th>FRD3</th>\n",
       "      <th>FRD4</th>\n",
       "      <th>FRD5</th>\n",
       "      <th>FRD6</th>\n",
       "      <th>FRD7</th>\n",
       "      <th>FRD8</th>\n",
       "      <th>FRD9</th>\n",
       "      <th>...</th>\n",
       "      <th>FRD14</th>\n",
       "      <th>FRD15</th>\n",
       "      <th>FRD16</th>\n",
       "      <th>FRD17</th>\n",
       "      <th>FRD18</th>\n",
       "      <th>FRD19</th>\n",
       "      <th>FRD20</th>\n",
       "      <th>FRD21</th>\n",
       "      <th>FRD22</th>\n",
       "      <th>FRD23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56859.0</td>\n",
       "      <td>53558.0</td>\n",
       "      <td>52054.0</td>\n",
       "      <td>48750.0</td>\n",
       "      <td>46996.0</td>\n",
       "      <td>46527.0</td>\n",
       "      <td>47756.0</td>\n",
       "      <td>49536.0</td>\n",
       "      <td>50979.0</td>\n",
       "      <td>51954.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47533.0</td>\n",
       "      <td>46260.0</td>\n",
       "      <td>46225.0</td>\n",
       "      <td>49270.0</td>\n",
       "      <td>53075.0</td>\n",
       "      <td>53745.0</td>\n",
       "      <td>51700.0</td>\n",
       "      <td>49405.0</td>\n",
       "      <td>49259.0</td>\n",
       "      <td>52641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49249.0</td>\n",
       "      <td>45931.0</td>\n",
       "      <td>44183.0</td>\n",
       "      <td>40586.0</td>\n",
       "      <td>38239.0</td>\n",
       "      <td>37683.0</td>\n",
       "      <td>38376.0</td>\n",
       "      <td>39370.0</td>\n",
       "      <td>40552.0</td>\n",
       "      <td>42431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42439.0</td>\n",
       "      <td>40791.0</td>\n",
       "      <td>41078.0</td>\n",
       "      <td>44423.0</td>\n",
       "      <td>48812.0</td>\n",
       "      <td>50620.0</td>\n",
       "      <td>48513.0</td>\n",
       "      <td>45708.0</td>\n",
       "      <td>43952.0</td>\n",
       "      <td>46982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44525.0</td>\n",
       "      <td>41357.0</td>\n",
       "      <td>40440.0</td>\n",
       "      <td>37573.0</td>\n",
       "      <td>36607.0</td>\n",
       "      <td>38698.0</td>\n",
       "      <td>44191.0</td>\n",
       "      <td>51885.0</td>\n",
       "      <td>54279.0</td>\n",
       "      <td>54481.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51789.0</td>\n",
       "      <td>50879.0</td>\n",
       "      <td>50999.0</td>\n",
       "      <td>54038.0</td>\n",
       "      <td>57924.0</td>\n",
       "      <td>59230.0</td>\n",
       "      <td>55192.0</td>\n",
       "      <td>50455.0</td>\n",
       "      <td>48569.0</td>\n",
       "      <td>52230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50071.0</td>\n",
       "      <td>47256.0</td>\n",
       "      <td>46225.0</td>\n",
       "      <td>43645.0</td>\n",
       "      <td>42713.0</td>\n",
       "      <td>45043.0</td>\n",
       "      <td>50775.0</td>\n",
       "      <td>58706.0</td>\n",
       "      <td>61990.0</td>\n",
       "      <td>62678.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60567.0</td>\n",
       "      <td>59258.0</td>\n",
       "      <td>59636.0</td>\n",
       "      <td>62990.0</td>\n",
       "      <td>66785.0</td>\n",
       "      <td>67992.0</td>\n",
       "      <td>63796.0</td>\n",
       "      <td>59746.0</td>\n",
       "      <td>58094.0</td>\n",
       "      <td>61111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57274.0</td>\n",
       "      <td>53753.0</td>\n",
       "      <td>52358.0</td>\n",
       "      <td>49462.0</td>\n",
       "      <td>48265.0</td>\n",
       "      <td>50100.0</td>\n",
       "      <td>55185.0</td>\n",
       "      <td>61469.0</td>\n",
       "      <td>64081.0</td>\n",
       "      <td>64091.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59158.0</td>\n",
       "      <td>57335.0</td>\n",
       "      <td>57344.0</td>\n",
       "      <td>60113.0</td>\n",
       "      <td>63325.0</td>\n",
       "      <td>64205.0</td>\n",
       "      <td>59807.0</td>\n",
       "      <td>55705.0</td>\n",
       "      <td>53553.0</td>\n",
       "      <td>56548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>49337.0</td>\n",
       "      <td>46808.0</td>\n",
       "      <td>45655.0</td>\n",
       "      <td>43403.0</td>\n",
       "      <td>41402.0</td>\n",
       "      <td>41468.0</td>\n",
       "      <td>44534.0</td>\n",
       "      <td>49401.0</td>\n",
       "      <td>51658.0</td>\n",
       "      <td>51053.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36750.0</td>\n",
       "      <td>38016.0</td>\n",
       "      <td>39306.0</td>\n",
       "      <td>42193.0</td>\n",
       "      <td>44089.0</td>\n",
       "      <td>44312.0</td>\n",
       "      <td>42632.0</td>\n",
       "      <td>40102.0</td>\n",
       "      <td>38973.0</td>\n",
       "      <td>41407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>37469.0</td>\n",
       "      <td>36747.0</td>\n",
       "      <td>36444.0</td>\n",
       "      <td>34598.0</td>\n",
       "      <td>33557.0</td>\n",
       "      <td>34864.0</td>\n",
       "      <td>36972.0</td>\n",
       "      <td>39739.0</td>\n",
       "      <td>42060.0</td>\n",
       "      <td>43070.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>37706.0</td>\n",
       "      <td>39291.0</td>\n",
       "      <td>42616.0</td>\n",
       "      <td>45704.0</td>\n",
       "      <td>47246.0</td>\n",
       "      <td>44528.0</td>\n",
       "      <td>41561.0</td>\n",
       "      <td>40344.0</td>\n",
       "      <td>42081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>39563.0</td>\n",
       "      <td>36971.0</td>\n",
       "      <td>36466.0</td>\n",
       "      <td>34115.0</td>\n",
       "      <td>32665.0</td>\n",
       "      <td>32956.0</td>\n",
       "      <td>35848.0</td>\n",
       "      <td>39241.0</td>\n",
       "      <td>41611.0</td>\n",
       "      <td>42992.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38885.0</td>\n",
       "      <td>39942.0</td>\n",
       "      <td>40880.0</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>47275.0</td>\n",
       "      <td>49004.0</td>\n",
       "      <td>46389.0</td>\n",
       "      <td>43717.0</td>\n",
       "      <td>42588.0</td>\n",
       "      <td>44865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>42237.0</td>\n",
       "      <td>39997.0</td>\n",
       "      <td>40029.0</td>\n",
       "      <td>37768.0</td>\n",
       "      <td>36802.0</td>\n",
       "      <td>36653.0</td>\n",
       "      <td>38198.0</td>\n",
       "      <td>40164.0</td>\n",
       "      <td>41996.0</td>\n",
       "      <td>42670.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34855.0</td>\n",
       "      <td>35899.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>39565.0</td>\n",
       "      <td>42056.0</td>\n",
       "      <td>42329.0</td>\n",
       "      <td>39691.0</td>\n",
       "      <td>37054.0</td>\n",
       "      <td>36866.0</td>\n",
       "      <td>38231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>35588.0</td>\n",
       "      <td>32520.0</td>\n",
       "      <td>30963.0</td>\n",
       "      <td>27763.0</td>\n",
       "      <td>25365.0</td>\n",
       "      <td>24916.0</td>\n",
       "      <td>26069.0</td>\n",
       "      <td>27073.0</td>\n",
       "      <td>29076.0</td>\n",
       "      <td>30833.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26891.0</td>\n",
       "      <td>27945.0</td>\n",
       "      <td>28537.0</td>\n",
       "      <td>32258.0</td>\n",
       "      <td>35434.0</td>\n",
       "      <td>35707.0</td>\n",
       "      <td>34774.0</td>\n",
       "      <td>33642.0</td>\n",
       "      <td>34910.0</td>\n",
       "      <td>37230.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FRD0     FRD1     FRD2     FRD3     FRD4     FRD5     FRD6     FRD7  \\\n",
       "0     56859.0  53558.0  52054.0  48750.0  46996.0  46527.0  47756.0  49536.0   \n",
       "1     49249.0  45931.0  44183.0  40586.0  38239.0  37683.0  38376.0  39370.0   \n",
       "2     44525.0  41357.0  40440.0  37573.0  36607.0  38698.0  44191.0  51885.0   \n",
       "3     50071.0  47256.0  46225.0  43645.0  42713.0  45043.0  50775.0  58706.0   \n",
       "4     57274.0  53753.0  52358.0  49462.0  48265.0  50100.0  55185.0  61469.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1852  49337.0  46808.0  45655.0  43403.0  41402.0  41468.0  44534.0  49401.0   \n",
       "1853  37469.0  36747.0  36444.0  34598.0  33557.0  34864.0  36972.0  39739.0   \n",
       "1854  39563.0  36971.0  36466.0  34115.0  32665.0  32956.0  35848.0  39241.0   \n",
       "1855  42237.0  39997.0  40029.0  37768.0  36802.0  36653.0  38198.0  40164.0   \n",
       "1856  35588.0  32520.0  30963.0  27763.0  25365.0  24916.0  26069.0  27073.0   \n",
       "\n",
       "         FRD8     FRD9  ...    FRD14    FRD15    FRD16    FRD17    FRD18  \\\n",
       "0     50979.0  51954.0  ...  47533.0  46260.0  46225.0  49270.0  53075.0   \n",
       "1     40552.0  42431.0  ...  42439.0  40791.0  41078.0  44423.0  48812.0   \n",
       "2     54279.0  54481.0  ...  51789.0  50879.0  50999.0  54038.0  57924.0   \n",
       "3     61990.0  62678.0  ...  60567.0  59258.0  59636.0  62990.0  66785.0   \n",
       "4     64081.0  64091.0  ...  59158.0  57335.0  57344.0  60113.0  63325.0   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "1852  51658.0  51053.0  ...  36750.0  38016.0  39306.0  42193.0  44089.0   \n",
       "1853  42060.0  43070.0  ...  36864.0  37706.0  39291.0  42616.0  45704.0   \n",
       "1854  41611.0  42992.0  ...  38885.0  39942.0  40880.0  43974.0  47275.0   \n",
       "1855  41996.0  42670.0  ...  34855.0  35899.0  36681.0  39565.0  42056.0   \n",
       "1856  29076.0  30833.0  ...  26891.0  27945.0  28537.0  32258.0  35434.0   \n",
       "\n",
       "        FRD19    FRD20    FRD21    FRD22    FRD23  \n",
       "0     53745.0  51700.0  49405.0  49259.0  52641.0  \n",
       "1     50620.0  48513.0  45708.0  43952.0  46982.0  \n",
       "2     59230.0  55192.0  50455.0  48569.0  52230.0  \n",
       "3     67992.0  63796.0  59746.0  58094.0  61111.0  \n",
       "4     64205.0  59807.0  55705.0  53553.0  56548.0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "1852  44312.0  42632.0  40102.0  38973.0  41407.0  \n",
       "1853  47246.0  44528.0  41561.0  40344.0  42081.0  \n",
       "1854  49004.0  46389.0  43717.0  42588.0  44865.0  \n",
       "1855  42329.0  39691.0  37054.0  36866.0  38231.0  \n",
       "1856  35707.0  34774.0  33642.0  34910.0  37230.0  \n",
       "\n",
       "[1857 rows x 24 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "from torch.optim import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaler_X.fit_transform(X).astype('float32')\n",
    "y=scaler_y.fit_transform(Y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, X,Y, batch_size):\n",
    "        self.X_ = X\n",
    "        self.Y_ = Y\n",
    "        self.batch_size_ = batch_size\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        print('Creation of the dataset ....')\n",
    "        # Convert Input and Output data to Tensors and create a TensorDataset \n",
    "        #X = torch.Tensor(scaler_X.fit_transform(self.X_.to_numpy(dtype='float32')))       # Create tensor of type torch.float32 \n",
    "        X = torch.Tensor(self.X_) \n",
    "        #Y = torch.tensor(scaler_y.fit_transform(self.Y_.to_numpy(dtype='float32')))  # Create tensor type torch.float32 of size (n,1)  \n",
    "        Y = torch.tensor(self.Y_)\n",
    "\n",
    "        data = TensorDataset(X, Y)\n",
    "        train_set, test_set = random_split(data, [0.8, 0.2]) \n",
    "\n",
    "        # Create Dataloader to read the data within batch sizes and put into memory. \n",
    "        train_loader = DataLoader(train_set, batch_size = self.batch_size_, shuffle = True) \n",
    "        test_loader = DataLoader(test_set, batch_size =1, drop_last=False)\n",
    "\n",
    "        print(\"Train et test datasets created !\")\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the dataset ....\n",
      "Train et test datasets created !\n"
     ]
    }
   ],
   "source": [
    "data = Data(X=x,Y=y,batch_size=64)\n",
    "    \n",
    "train, test = data.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, learning_rate, loss):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size_ = input_size\n",
    "        self.output_size_ = output_size\n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.loss_ = loss \n",
    "        self.mlp_ = nn.Sequential(\n",
    "            #nn.Flatten(),\n",
    "            nn.BatchNorm1d(num_features=self.input_size_),\n",
    "            nn.Linear(self.input_size_, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, 3000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3000, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,self.output_size_)\n",
    "        )\n",
    "        self.optimizer_ = Adam(self.mlp_.parameters(), lr=self.learning_rate_)\n",
    "\n",
    "    def forward(self, x):\n",
    "        value = self.mlp_(x)\n",
    "        return value\n",
    "    \n",
    "    def train(self, num_epoch, training_set):\n",
    "        #best_accuracy = 0.0\n",
    "        print(\"Training is beginning...\")\n",
    "\n",
    "        for epoch in range(1,num_epoch+1):\n",
    "            for data in training_set:\n",
    "                X,y = data \n",
    "                self.optimizer_.zero_grad()   # zero the parameter gradients          \n",
    "                predicted_outputs = self.forward(X)   # predict output from the model \n",
    "                #print(predicted_outputs)\n",
    "                #print(y.size())\n",
    "                train_loss = self.loss_(predicted_outputs, y)   # calculate loss for the predicted output\n",
    "                \n",
    "                train_loss.backward()   # backpropagate the loss \n",
    "                self.optimizer_.step()\n",
    "            print(f\"Epoch {epoch} : Loss : {train_loss}\")\n",
    "\n",
    "        print(\"Training is finished !\")\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        self.mlp_.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.mlp_(x_test)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is beginning...\n",
      "Epoch 1 : Loss : 0.010777143761515617\n",
      "Epoch 2 : Loss : 0.014680532738566399\n",
      "Epoch 3 : Loss : 0.015723535791039467\n",
      "Epoch 4 : Loss : 0.018414968624711037\n",
      "Epoch 5 : Loss : 0.03214017301797867\n",
      "Epoch 6 : Loss : 0.018546489998698235\n",
      "Epoch 7 : Loss : 0.004787443671375513\n",
      "Epoch 8 : Loss : 0.018249521031975746\n",
      "Epoch 9 : Loss : 0.0314156748354435\n",
      "Epoch 10 : Loss : 0.007348966784775257\n",
      "Training is finished !\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(input_size=24, \n",
    "                          output_size=24, \n",
    "                          learning_rate=1e-3, \n",
    "                          loss=nn.MSELoss())\n",
    "model.train(10,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 77.04919172  64.08130503  65.67581825  67.00259039  55.70528688\n",
      "   57.19839687  80.14628384  93.35970364  99.20053497 109.70594813\n",
      "   92.26434873  92.54911359 100.85136976  97.93717627  91.36443547\n",
      "   90.53340038  90.1444444   88.22999295 129.05645213 110.26050363\n",
      "  112.35786509  85.64442428  79.39211967  66.84148255]]\n",
      "[[56.18000106 55.26000157 54.67000171 48.16000175 46.56999575 48.8600007\n",
      "  50.05000077 65.39999804 62.11999741 68.45999859 67.78999972 70.77999935\n",
      "  70.70000196 69.50000239 68.77000047 73.59999633 65.63000008 74.75999827\n",
      "  78.92999938 77.09999876 70.00000205 60.0300012  61.5599982  59.97000026]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.11257416 0.10270572 0.11323006 0.16200545 0.15353319 0.124493\n 0.13761112 0.14727969 0.15003297 0.15702498 0.1466203  0.13963485\n 0.15129206 0.17464718 0.17966476 0.23878823 0.19171833 0.14215818\n 0.15157822 0.12235868 0.12916699 0.08385882 0.10420442 0.08885309].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(scaler_y\u001b[38;5;241m.\u001b[39minverse_transform(y_test))\n\u001b[0;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss(\u001b[43mscaler_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,scaler_y\u001b[38;5;241m.\u001b[39minverse_transform(y_test)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:565\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    561\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    563\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 565\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    573\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:989\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    984\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m             )\n\u001b[1;32m--> 989\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.11257416 0.10270572 0.11323006 0.16200545 0.15353319 0.124493\n 0.13761112 0.14727969 0.15003297 0.15702498 0.1466203  0.13963485\n 0.15129206 0.17464718 0.17966476 0.23878823 0.19171833 0.14215818\n 0.15157822 0.12235868 0.12916699 0.08385882 0.10420442 0.08885309].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "for x_test, y_test in test:\n",
    "    print(scaler_y.inverse_transform(model.predict(x_test)))\n",
    "    print(scaler_y.inverse_transform(y_test))\n",
    "    loss = nn.MSELoss()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114.74999804, 111.13999573, 108.95999789, ..., 134.2499979 ,\n",
       "        122.8200048 , 109.16000536],\n",
       "       [ 38.84000119,  37.70000051,  36.72999766, ...,  43.5300015 ,\n",
       "         43.38999988,  45.41999885],\n",
       "       [ 26.70999959,  18.89000109,  16.56000112, ...,  24.63000066,\n",
       "         32.44999895,  20.93999948],\n",
       "       ...,\n",
       "       [129.08000194, 114.63000079, 112.57000195, ..., 144.96000662,\n",
       "        140.04000556, 134.54999674],\n",
       "       [ 20.20000018,  19.21000067,  19.50000094, ...,  24.51000041,\n",
       "         24.02000032,  21.18000002],\n",
       "       [199.49999697, 192.52999497, 192.77999929, ..., 270.00000514,\n",
       "        258.84998962, 247.69000954]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>DAP</th>\n",
       "      <th>Residual_Demand</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17753</th>\n",
       "      <td>2020-12-09 17:00:00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>70968.0</td>\n",
       "      <td>2020-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18475</th>\n",
       "      <td>2021-01-08 19:00:00</td>\n",
       "      <td>114.89</td>\n",
       "      <td>83532.0</td>\n",
       "      <td>2021-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23456</th>\n",
       "      <td>2021-08-04 08:00:00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>40284.0</td>\n",
       "      <td>2021-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23457</th>\n",
       "      <td>2021-08-04 09:00:00</td>\n",
       "      <td>114.68</td>\n",
       "      <td>42558.0</td>\n",
       "      <td>2021-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23600</th>\n",
       "      <td>2021-08-10 08:00:00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>37238.0</td>\n",
       "      <td>2021-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43861</th>\n",
       "      <td>2023-12-02 13:00:00</td>\n",
       "      <td>114.58</td>\n",
       "      <td>54356.0</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43887</th>\n",
       "      <td>2023-12-03 15:00:00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>47413.0</td>\n",
       "      <td>2023-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43916</th>\n",
       "      <td>2023-12-04 20:00:00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>54395.0</td>\n",
       "      <td>2023-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44084</th>\n",
       "      <td>2023-12-11 20:00:00</td>\n",
       "      <td>114.41</td>\n",
       "      <td>54408.0</td>\n",
       "      <td>2023-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44155</th>\n",
       "      <td>2023-12-14 19:00:00</td>\n",
       "      <td>114.43</td>\n",
       "      <td>63311.0</td>\n",
       "      <td>2023-12-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp     DAP  Residual_Demand        Date\n",
       "17753 2020-12-09 17:00:00  114.00          70968.0  2020-12-09\n",
       "18475 2021-01-08 19:00:00  114.89          83532.0  2021-01-08\n",
       "23456 2021-08-04 08:00:00  115.00          40284.0  2021-08-04\n",
       "23457 2021-08-04 09:00:00  114.68          42558.0  2021-08-04\n",
       "23600 2021-08-10 08:00:00  115.00          37238.0  2021-08-10\n",
       "...                   ...     ...              ...         ...\n",
       "43861 2023-12-02 13:00:00  114.58          54356.0  2023-12-02\n",
       "43887 2023-12-03 15:00:00  115.00          47413.0  2023-12-03\n",
       "43916 2023-12-04 20:00:00  115.00          54395.0  2023-12-04\n",
       "44084 2023-12-11 20:00:00  114.41          54408.0  2023-12-11\n",
       "44155 2023-12-14 19:00:00  114.43          63311.0  2023-12-14\n",
       "\n",
       "[124 rows x 4 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['DAP'].between(114,115)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
